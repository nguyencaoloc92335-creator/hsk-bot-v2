import google.generativeai as genai
import json
import re
import logging
from config import GEMINI_API_KEY

logger = logging.getLogger(__name__)

model = None

def setup_and_auto_pick_model():
    """
    H√†m n√†y KH√îNG ƒëo√°n t√™n model.
    N√≥ h·ªèi Google danh s√°ch v√† l·∫•y c√°i ƒë·∫ßu ti√™n d√πng ƒë∆∞·ª£c.
    """
    global model
    if not GEMINI_API_KEY:
        logger.error("‚ùå Ch∆∞a c√≥ GEMINI_API_KEY")
        return

    try:
        genai.configure(api_key=GEMINI_API_KEY)
        
        logger.info("üîç ƒêANG QU√âT DANH S√ÅCH MODEL T·ª™ T√ÄI KHO·∫¢N C·ª¶A B·∫†N...")
        
        found_model_name = None
        
        # G·ªçi h√†m ListModels nh∆∞ g·ª£i √Ω c·ªßa Google
        for m in genai.list_models():
            # In ra log ƒë·ªÉ b·∫°n xem c√≥ nh·ªØng c√°i g√¨
            logger.info(f"üëâ T√¨m th·∫•y: {m.name} | Method: {m.supported_generation_methods}")
            
            # Ch·ªâ l·∫•y model h·ªó tr·ª£ t·∫°o n·ªôi dung (generateContent)
            if 'generateContent' in m.supported_generation_methods:
                # ∆Øu ti√™n l·∫•y b·∫£n Flash ho·∫∑c Pro n·∫øu th·∫•y
                if 'flash' in m.name:
                    found_model_name = m.name
                    break # T√¨m th·∫•y Flash l√† ch·ªët lu√¥n
                
                # N·∫øu ch∆∞a c√≥ Flash, t·∫°m l∆∞u c√°i n√†y l·∫°i (v√≠ d·ª• gemini-pro)
                if not found_model_name:
                    found_model_name = m.name

        if found_model_name:
            logger.info(f"‚úÖ CH·ªêT D√ôNG MODEL: {found_model_name}")
            # Kh·ªüi t·∫°o model v·ªõi c√°i t√™n ch√≠nh x√°c v·ª´a t√¨m ƒë∆∞·ª£c
            model = genai.GenerativeModel(found_model_name)
            
            # Test ngay l·∫≠p t·ª©c
            try:
                model.generate_content("Test connection")
                logger.info("üéâ K·∫æT N·ªêI AI TH√ÄNH C√îNG R·ª∞C R·ª†!")
            except Exception as e:
                logger.error(f"‚ö†Ô∏è Model {found_model_name} kh·ªüi t·∫°o ƒë∆∞·ª£c nh∆∞ng l·ªói khi g·ªçi: {e}")
        else:
            logger.error("‚ùå KH√îNG T√åM TH·∫§Y B·∫§T K·ª≤ MODEL N√ÄO CHO PH√âP GENERATE CONTENT.")

    except Exception as e:
        logger.error(f"‚ùå L·ªñI NGHI√äM TR·ªåNG KHI QU√âT MODEL: {e}")
        model = None

# Ch·∫°y h√†m n√†y ngay khi kh·ªüi ƒë·ªông
setup_and_auto_pick_model()

def clean_json_response(text):
    try:
        text = text.replace('```json', '').replace('```', '').strip()
        match = re.search(r'\{.*\}', text, re.DOTALL)
        if match: return json.loads(match.group())
        return json.loads(text)
    except: return None

def lookup_word(text):
    if not model: return None
    try:
        # Prompt ƒë∆°n gi·∫£n
        prompt = f"""Tra t·ª´: "{text}". Tr·∫£ JSON: {{\"hanzi\": \"{text}\", \"pinyin\": \"...\", \"meaning\": \"...\"}}. N·∫øu ko ph·∫£i t·ª´ c√≥ nghƒ©a tr·∫£ null."""
        response = model.generate_content(prompt)
        return clean_json_response(response.text)
    except Exception as e:
        logger.error(f"Tra t·ª´ l·ªói: {e}")
        return None

def generate_example(word):
    hanzi = word.get('H√°n t·ª±','')
    meaning = word.get('Nghƒ©a','')
    backup = {"han": f"{hanzi}", "pinyin": "...", "viet": f"{meaning}"}
    if not model: return backup
    try:
        prompt = f"ƒê·∫∑t c√¢u v√≠ d·ª• HSK 1 v·ªõi: {hanzi} ({meaning}). Tr·∫£ JSON: {{\"han\": \"...\", \"pinyin\": \"...\", \"viet\": \"...\"}}"
        response = model.generate_content(prompt)
        res = clean_json_response(response.text)
        return res if res else backup
    except: return backup

def chat_reply(text):
    if not model: return "H·ªá th·ªëng AI ƒëang b·∫£o tr√¨ (L·ªói Model)."
    try:
        response = model.generate_content(f"B·∫°n l√† bot ti·∫øng Trung. User: '{text}'. Tr·∫£ l·ªùi ng·∫Øn g·ªçn ti·∫øng Vi·ªát.")
        return response.text.strip()
    except: return "H·ªá th·ªëng b·∫≠n."
