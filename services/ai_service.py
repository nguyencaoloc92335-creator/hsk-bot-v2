import google.generativeai as genai
import json
import re
import logging
import os # Import os ƒë·ªÉ l·∫•y key t·ª´ bi·∫øn m√¥i tr∆∞·ªùng

logger = logging.getLogger(__name__)

# L·∫§Y KEY T·ª™ BI·∫æN M√îI TR∆Ø·ªúNG (AN TO√ÄN TUY·ªÜT ƒê·ªêI)
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

model = None

def setup_and_auto_pick_model():
    global model
    if not GEMINI_API_KEY:
        logger.error("‚ùå Ch∆∞a c·∫•u h√¨nh GEMINI_API_KEY trong Environment Variables!")
        return

    try:
        genai.configure(api_key=GEMINI_API_KEY)
        # ∆Øu ti√™n t√¨m Flash ho·∫∑c Pro
        target_models = ['gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro']
        
        # L·∫•y danh s√°ch th·ª±c t·∫ø
        available = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        logger.info(f"üìã C√°c model kh·∫£ d·ª•ng: {available}")

        chosen_model = None
        # Thu·∫≠t to√°n t√¨m model:
        for target in target_models:
            for real in available:
                if target in real:
                    chosen_model = real
                    break
            if chosen_model: break
        
        # Fallback n·∫øu kh√¥ng kh·ªõp t√™n n√†o (l·∫•y c√°i ƒë·∫ßu ti√™n)
        if not chosen_model and available:
            chosen_model = available[0]

        if chosen_model:
            logger.info(f"‚úÖ ƒê√£ ch·ªçn Model: {chosen_model}")
            model = genai.GenerativeModel(chosen_model)
        else:
            logger.error("‚ùå Kh√¥ng t√¨m th·∫•y Model n√†o d√πng ƒë∆∞·ª£c!")

    except Exception as e:
        logger.error(f"‚ùå L·ªói kh·ªüi t·∫°o AI: {e}")

setup_and_auto_pick_model()

def clean_json_response(text):
    try:
        text = text.replace('```json', '').replace('```', '').strip()
        match = re.search(r'\{.*\}', text, re.DOTALL)
        if match: return json.loads(match.group())
        return json.loads(text)
    except: return None

def lookup_word(text):
    if not model: return None
    try:
        prompt = f"""Tra t·ª´: "{text}". Tr·∫£ JSON: {{\"hanzi\": \"{text}\", \"pinyin\": \"...\", \"meaning\": \"...\"}}. N·∫øu ko ph·∫£i t·ª´ c√≥ nghƒ©a tr·∫£ null."""
        response = model.generate_content(prompt)
        return clean_json_response(response.text)
    except: return None

def generate_example(word):
    hanzi = word.get('H√°n t·ª±','')
    meaning = word.get('Nghƒ©a','')
    backup = {"han": f"{hanzi}", "pinyin": "...", "viet": f"{meaning}"}
    if not model: return backup
    try:
        prompt = f"ƒê·∫∑t c√¢u v√≠ d·ª• HSK 1 v·ªõi: {hanzi} ({meaning}). Tr·∫£ JSON: {{\"han\": \"...\", \"pinyin\": \"...\", \"viet\": \"...\"}}"
        response = model.generate_content(prompt)
        res = clean_json_response(response.text)
        return res if res else backup
    except: return backup

def chat_reply(text):
    if not model: return "Bot ƒëang b·∫£o tr√¨ AI."
    try:
        # Prompt ƒë∆°n gi·∫£n ƒë·ªÉ ti·∫øt ki·ªám token
        response = model.generate_content(f"User: '{text}'. Tr·∫£ l·ªùi ng·∫Øn g·ªçn ti·∫øng Vi·ªát.")
        return response.text.strip()
    except: return "H·ªá th·ªëng b·∫≠n."
